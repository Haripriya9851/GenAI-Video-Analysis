{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SybqQbDmeiL5",
        "outputId": "e0001611-ff62-4ad4-f308-50fee35f3766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.43.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pytube openai moviepy opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll8bXS0VlckJ"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq8Iv1EodmbQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "import uuid\n",
        "from pytube import YouTube\n",
        "import cv2\n",
        "from moviepy.editor import AudioFileClip\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "class YoutubeVideoAnalysis:\n",
        "    \"\"\"\n",
        "    A class used to analyze YouTube videos.\n",
        "\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    openai_api_key : str\n",
        "        The API key for OpenAI.\n",
        "    vision_model_base_url : str\n",
        "        The base URL for the vision model.\n",
        "    vision_model : str\n",
        "        The name of the vision model.\n",
        "    whisper_model : str\n",
        "        The name of the whisper model.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    analyse_video(query: str, video_url: str) -> str:\n",
        "        Analyzes the video and extracts insights.\n",
        "    _process_video(video_url: str, seconds_per_frame=2):\n",
        "        Extracts frames and audio from a video file.\n",
        "    _transcribe(audio_path):\n",
        "        Generates a summary of the audio transcription.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vision_model_base_url: str,\n",
        "        vision_model: str,\n",
        "        openai_api_key: str,\n",
        "        whisper_model: str = \"base\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Constructs all the necessary attributes for the YoutubeVideoAnalysis object.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            vision_model_base_url : str\n",
        "                The base URL for the vision model.\n",
        "            vision_model : str\n",
        "                The name of the vision model.\n",
        "            openai_api_key : str\n",
        "                The API key for OpenAI.\n",
        "            whisper_model : str\n",
        "                The name of the whisper model.\n",
        "        \"\"\"\n",
        "        self.vision_model_base_url = vision_model_base_url\n",
        "        self.vision_model = vision_model\n",
        "        self.llm = OpenAI(api_key=openai_api_key, base_url=vision_model_base_url)\n",
        "        self.whisper_model = whisper_model\n",
        "\n",
        "    def analyse_video(self, query: str, video_url: str) -> str:\n",
        "        \"\"\"\n",
        "        Analyzes the video and extracts insights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            query : str\n",
        "                The query to analyze.\n",
        "            video_url : str\n",
        "                The URL of the YouTube video.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            str\n",
        "                The analysis result.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            base64_frames, audio_path = self._process_video(video_url)\n",
        "            audio_transcription = self._transcribe(audio_path)\n",
        "        except Exception as e:\n",
        "            return f\"Error processing video: {e}\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.Completions.create(\n",
        "                model=self.vision_model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a video analysis tool. Please answer any questions about the given video.\",\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            f\"This is the query: {query}\\n\",\n",
        "                            f\"This is the video's audio transcription: {audio_transcription}\\n\",\n",
        "                            \"Here are the frames from the video.\",\n",
        "                            *map(\n",
        "                                lambda x: {\n",
        "                                    \"type\": \"image_url\",\n",
        "                                    \"image_url\": {\n",
        "                                        \"url\": f\"data:image/jpeg;base64,{x}\",\n",
        "                                        \"detail\": \"low\",\n",
        "                                    },\n",
        "                                },\n",
        "                                base64_frames[::5],\n",
        "                            ),\n",
        "                        ],\n",
        "                    },\n",
        "                ],\n",
        "                temperature=0,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            return f\"Error creating completion: {e}\"\n",
        "\n",
        "        return response.choices[0].message['content']\n",
        "\n",
        "    def _process_video(self, video_url: str, seconds_per_frame=2):\n",
        "        \"\"\"\n",
        "        Extracts frames and audio from a video file.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            video_url : str\n",
        "                The URL of the YouTube video.\n",
        "            seconds_per_frame : int, optional\n",
        "                The number of seconds per frame (default is 2).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            list\n",
        "                The list of base64-encoded frames.\n",
        "            str\n",
        "                The path to the audio file.\n",
        "        \"\"\"\n",
        "        base64_frames = []\n",
        "\n",
        "        # Define the directory for temporary files\n",
        "        temp_dir = os.path.join(os.getcwd(), \"temp_tool_files\")\n",
        "\n",
        "        # Make sure the directory exists\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        # Create a YouTube object\n",
        "        yt = YouTube(video_url)\n",
        "        print(\"Video Downloaded 1!\")\n",
        "\n",
        "\n",
        "        # Generate a unique identifier for the video\n",
        "        video_id = str(uuid.uuid4())\n",
        "        print(video_id)\n",
        "\n",
        "        # Download the video file\n",
        "        yt.streams.first().download(output_path=temp_dir, filename=f\"{video_id}.mp4\")\n",
        "        print(\"Video Downloaded 2!\")\n",
        "\n",
        "        # Define the path for the temporary video file\n",
        "        temp_file_path = os.path.join(temp_dir, f\"{video_id}.mp4\")\n",
        "\n",
        "        # Update the video path to the temporary file path\n",
        "        video_path = temp_file_path\n",
        "\n",
        "        base_video_path, _ = os.path.splitext(video_path)\n",
        "\n",
        "        try:\n",
        "            video = cv2.VideoCapture(video_path)\n",
        "            total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            fps = video.get(cv2.CAP_PROP_FPS)\n",
        "            frames_to_skip = int(fps * seconds_per_frame)\n",
        "            curr_frame = 0\n",
        "\n",
        "            while curr_frame < total_frames - 1:\n",
        "                video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
        "                success, frame = video.read()\n",
        "                if not success:\n",
        "                    break\n",
        "                _, buffer = cv2.imencode(\".jpg\", frame)\n",
        "                base64_frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
        "                curr_frame += frames_to_skip\n",
        "            video.release()\n",
        "\n",
        "            # Extract audio with moviepy\n",
        "            audio_path = f\"{base_video_path}.mp3\"\n",
        "            audio_clip = AudioFileClip(video_path)\n",
        "            audio_clip.write_audiofile(audio_path, bitrate=\"32k\")\n",
        "            audio_clip.close()\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error processing video: {e}\")\n",
        "        finally:\n",
        "            # Once done, delete the video file\n",
        "            if os.path.exists(video_path):\n",
        "                os.remove(video_path)\n",
        "\n",
        "\n",
        "        return base64_frames, audio_path\n",
        "\n",
        "    def _transcribe(self, audio_path):\n",
        "        \"\"\"\n",
        "        Generates a summary of the audio transcription.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            audio_path : str\n",
        "                The path to the audio file.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            str\n",
        "                The transcription text.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with open(audio_path, \"rb\") as audio_file:\n",
        "                transcription = self.llm.Audio.transcriptions.create(\n",
        "                    model=self.whisper_model,\n",
        "                    file=audio_file,\n",
        "                )\n",
        "            return transcription['text']\n",
        "        finally:\n",
        "            # Clean up the audio file\n",
        "            if os.path.exists(audio_path):\n",
        "                os.remove(audio_path)\n",
        "\n",
        "\n",
        "def example_usage():\n",
        "    \"\"\"Example usage of the YoutubeVideoAnalysis class.\"\"\"\n",
        "    openai_api_key = \"KEY\"\n",
        "    vision_model_base_url = \"https://api.openai.com/v1\"\n",
        "    vision_model = \"gpt-4o-mini\"\n",
        "\n",
        "    youtube_video_analysis = YoutubeVideoAnalysis(\n",
        "        openai_api_key=openai_api_key,\n",
        "        vision_model_base_url=vision_model_base_url,\n",
        "        vision_model=vision_model,\n",
        "    )\n",
        "\n",
        "    result = youtube_video_analysis.analyse_video(\n",
        "        query=\"What is this video about and what sort of imagery is used?\",\n",
        "        #video_url=\"https://www.youtube.com/watch?v=p9CCSG3-dhI\"  # Example URL\n",
        "        video_url=\"https://www.youtube.com/watch?v=0N9H1SHL6Pg\"\n",
        "    )\n",
        "\n",
        "    print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    example_usage()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixdkuaq1gPlB"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
